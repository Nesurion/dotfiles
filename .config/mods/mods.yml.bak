# Default model (gpt-3.5-turbo, gpt-4, ggml-gpt4all-j...).
# default-model: gpt-4o
# default-model: flash
default-model: codex-mini
# Text to append when using the -f flag.
format-text:
  markdown: "Format the response as markdown without enclosing backticks."
  json: "Format the response as json without enclosing backticks."
# List of predefined system messages that can be used as roles.
roles:
  "default": []
  config_commit:
    - "You are an expert at writing git commit messages."
    - "Your task is to write a clear and concise commit message based on the provided git diff."
    - "The commit message must follow the Conventional Commits specification."
    - "The `description` must be a short summary of the code changes, in the imperative mood."
    - "After the summary, add a blank line, followed by a more detailed description of the changes if necessary."
    - "Only return the raw commit message. Do not add ``` markers or any other explanatory text."
  pr:
    - "You are a git expert."
    - "Your task is to write a pull request summary."
    - "The user will provide a git diff, and you will create a pull request summary."
    - "The summary should be a short bullet points list."
    - "The summary should describe the changes in the diff."
  shell:
    - "you are a shell expert"
    - "you do not explain anything"
    - "you simply output one liners to solve the problems you're asked"
    - "you do not provide any explanation whatsoever, ONLY the command"
  # Example, a role called `shell`:
  # shell:
  #   - you are a shell expert
  #   - you do not explain anything
  #   - you simply output one liners to solve the problems you're asked
  #   - you do not provide any explanation whatsoever, ONLY the command
# Ask for the response to be formatted as markdown unless otherwise set.
format: false
# System role to use.
role: "default"
# Render output as raw text when connected to a TTY.
raw: false
# Quiet mode (hide the spinner while loading and stderr messages for success).
quiet: false
# Temperature (randomness) of results, from 0.0 to 2.0.
temp: 1.0
# TopP, an alternative to temperature that narrows response, from 0.0 to 1.0.
topp: 1.0
# TopK, only sample from the top K options for each subsequent token.
topk: 50
# Turn off the client-side limit on the size of the input into the model.
no-limit: false
# Wrap formatted output at specific width (default is 80)
word-wrap: 80
# Include the prompt from the arguments in the response.
include-prompt-args: false
# Include the prompt from the arguments and stdin, truncate stdin to specified number of lines.
include-prompt: 0
# Maximum number of times to retry API calls.
max-retries: 5
# Your desired level of fanciness.
fanciness: 10
# Text to show while generating.
status-text: Generating
# Theme to use in the forms. Valid units are: 'charm', 'catppuccin', 'dracula', and 'base16'
theme: charm
# Default character limit on input to model.
max-input-chars: 12250
# Maximum number of tokens in response.
# max-tokens: 100
#
max-completion-tokens: 100
# Aliases and endpoints for OpenAI compatible REST API.
apis:
  azure:
    # Set to 'azure-ad' to use Active Directory
    # Azure OpenAI setup: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource
    base-url: https://lxproductinternal.openai.azure.com/
    api-key:
    api-key-env: AZURE_OPENAI_KEY
    models:
      openai-gpt-4o-mini-deployment:
        max-input-chars: 128000
      gpt-4.1:
        aliases: ["az4.1"]
        max-input-chars: 128000
      gpt-4.1-mini:
        max-input-chars: 128000
      gpt-4:
        aliases: ["az4"]
        max-input-chars: 24500
        fallback: gpt-35-turbo
      gpt-35-turbo:
        aliases: ["az35t"]
        max-input-chars: 12250
        fallback: gpt-35
      gpt-35:
        aliases: ["az35"]
        max-input-chars: 12250
        fallback:
      o1-preview:
        aliases: ["o1-preview"]
        max-input-chars: 128000
      o4-mini:
        aliases: ["o4-mini"]
        max-input-chars: 128000
      codex-mini:
        max-input-chars: 12250
